#!/usr/bin/env python3
"""
å¯¹æ¯”è¯„ä¼°å‡½æ•°å’Œé¢„æµ‹å‡½æ•°åœ¨ç±»åˆ«9ä¸Šçš„è¡¨ç°
ä½¿ç”¨ç›¸åŒçš„æ•°æ®å’Œæ¨¡å‹ï¼Œæ‰¾å‡ºå·®å¼‚æ‰€åœ¨
"""

import sys
import os
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
import torchvision.transforms as transforms
from collections import Counter
import yaml

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

def load_class9_images():
    """åŠ è½½æ‰€æœ‰ç±»åˆ«9çš„å›¾ç‰‡è·¯å¾„"""
    print("ğŸ“Š åŠ è½½ç±»åˆ«9å›¾ç‰‡è·¯å¾„...")
    
    # æŸ¥æ‰¾æµ‹è¯•é›†æ–‡ä»¶
    possible_paths = [
        "data/annotations/cls_test.txt",
        "/var/yjs/zes/vgg/data/annotations/cls_test.txt",
        "../data/annotations/cls_test.txt",
        "../../data/annotations/cls_test.txt"
    ]
    
    test_file = None
    for path in possible_paths:
        if os.path.exists(path):
            test_file = path
            break
    
    if test_file is None:
        print("âŒ æµ‹è¯•é›†æ–‡ä»¶ä¸å­˜åœ¨")
        return None
    
    print(f"âœ… æ‰¾åˆ°æµ‹è¯•é›†æ–‡ä»¶: {test_file}")
    
    # è¯»å–æµ‹è¯•é›†æ•°æ®
    with open(test_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    lines = [line.strip() for line in lines if line.strip()]
    
    # ç­›é€‰ç±»åˆ«9çš„å›¾ç‰‡
    class9_paths = []
    class9_annotations = []
    
    for line in lines:
        parts = line.split(';')
        if len(parts) >= 2:
            class_id = int(parts[0])
            image_path = parts[1]
            
            if class_id == 8:  # ç±»åˆ«9å¯¹åº”ç´¢å¼•8
                class9_paths.append(image_path)
                class9_annotations.append(line)
    
    print(f"æ‰¾åˆ° {len(class9_paths)} ä¸ªç±»åˆ«9å›¾ç‰‡")
    print("ç¤ºä¾‹è·¯å¾„:")
    for i, path in enumerate(class9_paths[:3]):
        print(f"   {i+1}: {path}")
    
    return class9_paths, class9_annotations

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_paths = [
        "configs/training_config.yaml",
        "/var/yjs/zes/vgg/configs/training_config.yaml",
        "../configs/training_config.yaml"
    ]
    
    for path in config_paths:
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            print(f"âœ… åŠ è½½é…ç½®æ–‡ä»¶: {path}")
            return config
    
    print("âŒ æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶")
    return None

def load_model():
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print("ğŸ¤– åŠ è½½æ¨¡å‹...")
    
    config = load_config()
    if config is None:
        return None, None
    
    # å¯¼å…¥æ¨¡å‹å·¥å‚
    from src.models import create_model
    
    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    model_paths = [
        "models/checkpoints/latest/best_model.pth",
        "/var/yjs/zes/vgg/models/checkpoints/latest/best_model.pth",
        "../models/checkpoints/latest/best_model.pth"
    ]
    
    model_path = None
    for path in model_paths:
        if os.path.exists(path):
            model_path = path
            break
    
    if model_path is None:
        print("âŒ æ— æ³•æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
        return None, None
    
    print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
    
    # åˆ›å»ºæ¨¡å‹
    model_config = config['model'].copy()
    model_config['num_classes'] = config['data']['num_classes']
    model_config['pretrained'] = False
    
    model = create_model(model_config)
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ: {model_config['name']}")
    
    # åŠ è½½æƒé‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    state_dict = torch.load(model_path, map_location=device)
    if isinstance(state_dict, dict) and 'model_state_dict' in state_dict:
        model.load_state_dict(state_dict['model_state_dict'])
    else:
        model.load_state_dict(state_dict)
    
    model.to(device)
    model.eval()
    print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
    
    return model, config

def test_with_evaluation_function():
    """ä½¿ç”¨è¯„ä¼°å‡½æ•°æµ‹è¯•ç±»åˆ«9"""
    print("\nğŸ§ª ä½¿ç”¨è¯„ä¼°å‡½æ•°æµ‹è¯•ç±»åˆ«9...")
    
    try:
        # å¯¼å…¥è¯„ä¼°ç›¸å…³æ¨¡å—
        from src.data.dataset import DataGenerator
        from torch.utils.data import DataLoader
        
        # åŠ è½½æ•°æ®å’Œæ¨¡å‹
        class9_paths, class9_annotations = load_class9_images()
        model, config = load_model()
        
        if class9_paths is None or model is None:
            return None
        
        # åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨
        input_shape = config['data']['input_shape']
        dataset = DataGenerator(class9_annotations, input_shape, random=False)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        batch_size = config['dataloader']['batch_size']
        dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=0,
            drop_last=False
        )
        
        print(f"è¯„ä¼°å‡½æ•°æ•°æ®åŠ è½½å™¨:")
        print(f"   æ ·æœ¬æ•°: {len(dataset)}")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
        
        # è¿è¡Œè¯„ä¼°
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        y_true = []
        y_pred = []
        y_prob = []
        image_paths = []
        
        print("å¼€å§‹è¯„ä¼°...")
        with torch.no_grad():
            for batch_idx, (images, labels, paths) in enumerate(dataloader):
                images = images.to(device)
                labels = labels.to(device)
                
                # å‰å‘ä¼ æ’­
                outputs = model(images)
                probabilities = F.softmax(outputs, dim=1)
                
                # è·å–é¢„æµ‹ç»“æœ
                _, predicted = torch.max(outputs.data, 1)
                
                # æ”¶é›†ç»“æœ
                y_true.extend(labels.cpu().numpy())
                y_pred.extend(predicted.cpu().numpy())
                y_prob.extend(probabilities.cpu().numpy())
                image_paths.extend(paths)
        
        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        y_prob = np.array(y_prob)
        
        # è®¡ç®—å‡†ç¡®ç‡
        accuracy = np.mean(y_true == y_pred)
        correct_count = np.sum(y_true == y_pred)
        error_count = len(y_true) - correct_count
        
        print(f"âœ… è¯„ä¼°å‡½æ•°ç»“æœ:")
        print(f"   æ€»æ ·æœ¬æ•°: {len(y_true)}")
        print(f"   æ­£ç¡®é¢„æµ‹: {correct_count}")
        print(f"   é”™è¯¯é¢„æµ‹: {error_count}")
        print(f"   å‡†ç¡®ç‡: {accuracy:.4f}")
        
        # åˆ†æé¢„æµ‹åˆ†å¸ƒ
        pred_counter = Counter(y_pred)
        print(f"   é¢„æµ‹åˆ†å¸ƒ: {dict(pred_counter)}")
        
        return {
            'y_true': y_true,
            'y_pred': y_pred,
            'y_prob': y_prob,
            'image_paths': image_paths,
            'accuracy': accuracy,
            'correct_count': correct_count,
            'error_count': error_count
        }
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def preprocess_input(x):
    """
    è®­ç»ƒæ—¶ä½¿ç”¨çš„é¢„å¤„ç†å‡½æ•°
    å°†åƒç´ å€¼ä» [0, 255] èŒƒå›´è½¬æ¢åˆ° [-1, 1] èŒƒå›´
    """
    x /= 127.5
    x -= 1.
    return x

def get_transform(config):
    """è·å–ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„æ•°æ®é¢„å¤„ç†"""
    input_shape = config['data']['input_shape']
    
    # æ ¹æ®è®­ç»ƒæ—¶çš„é¢„å¤„ç†åˆ›å»ºtransform
    # æ³¨æ„ï¼šä¸ä½¿ç”¨ImageNetå½’ä¸€åŒ–ï¼Œè€Œæ˜¯ä½¿ç”¨è‡ªå®šä¹‰çš„preprocess_input
    transform = transforms.Compose([
        transforms.Resize((input_shape[0], input_shape[1])),
        transforms.ToTensor(),  # è½¬æ¢åˆ°[0,1]èŒƒå›´
        transforms.Lambda(lambda x: preprocess_input(x * 255.0))  # è½¬æ¢åˆ°[-1,1]èŒƒå›´
    ])
    
    return transform

def test_with_prediction_function():
    """ä½¿ç”¨é¢„æµ‹å‡½æ•°æµ‹è¯•ç±»åˆ«9"""
    print("\nğŸ” ä½¿ç”¨é¢„æµ‹å‡½æ•°æµ‹è¯•ç±»åˆ«9...")
    
    try:
        # åŠ è½½æ•°æ®å’Œæ¨¡å‹
        class9_paths, class9_annotations = load_class9_images()
        model, config = load_model()
        
        if class9_paths is None or model is None:
            return None
        
        # è·å–æ•°æ®é¢„å¤„ç†
        transform = get_transform(config)
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        y_true = []
        y_pred = []
        y_prob = []
        successful_paths = []
        
        print(f"é¢„æµ‹å‡½æ•°å¤„ç† {len(class9_paths)} ä¸ªå›¾ç‰‡...")
        
        for i, image_path in enumerate(class9_paths):
            try:
                # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not os.path.exists(image_path):
                    print(f"âš ï¸  å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
                    continue
                
                # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
                image = Image.open(image_path).convert('RGB')
                input_tensor = transform(image).unsqueeze(0).to(device)
                
                # é¢„æµ‹
                with torch.no_grad():
                    outputs = model(input_tensor)
                    probabilities = F.softmax(outputs, dim=1)
                    _, predicted = torch.max(outputs.data, 1)
                
                # æ”¶é›†ç»“æœ
                y_true.append(8)  # çœŸå®æ ‡ç­¾æ˜¯ç±»åˆ«9ï¼ˆç´¢å¼•8ï¼‰
                y_pred.append(predicted.cpu().item())
                y_prob.append(probabilities.cpu().numpy()[0])
                successful_paths.append(image_path)
                
                if (i + 1) % 20 == 0:
                    print(f"   å·²å¤„ç†: {i + 1}/{len(class9_paths)}")
                
            except Exception as e:
                print(f"âš ï¸  å¤„ç†å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
                continue
        
        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        y_prob = np.array(y_prob)
        
        # è®¡ç®—å‡†ç¡®ç‡
        accuracy = np.mean(y_true == y_pred)
        correct_count = np.sum(y_true == y_pred)
        error_count = len(y_true) - correct_count
        
        print(f"âœ… é¢„æµ‹å‡½æ•°ç»“æœ:")
        print(f"   æˆåŠŸå¤„ç†: {len(successful_paths)}")
        print(f"   æ­£ç¡®é¢„æµ‹: {correct_count}")
        print(f"   é”™è¯¯é¢„æµ‹: {error_count}")
        print(f"   å‡†ç¡®ç‡: {accuracy:.4f}")
        
        # åˆ†æé¢„æµ‹åˆ†å¸ƒ
        pred_counter = Counter(y_pred)
        print(f"   é¢„æµ‹åˆ†å¸ƒ: {dict(pred_counter)}")
        
        return {
            'y_true': y_true,
            'y_pred': y_pred,
            'y_prob': y_prob,
            'image_paths': successful_paths,
            'accuracy': accuracy,
            'correct_count': correct_count,
            'error_count': error_count
        }
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def compare_results(eval_result, pred_result):
    """å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„ç»“æœ"""
    print("\nğŸ“Š å¯¹æ¯”ç»“æœ...")
    
    if eval_result is None or pred_result is None:
        print("âŒ æ— æ³•å¯¹æ¯”ï¼ŒæŸä¸ªæµ‹è¯•å¤±è´¥")
        return
    
    print("="*60)
    print(f"ğŸ“‹ ç»“æœå¯¹æ¯”:")
    print(f"   è¯„ä¼°å‡½æ•° - æ ·æœ¬æ•°: {len(eval_result['y_true'])}, å‡†ç¡®ç‡: {eval_result['accuracy']:.4f}")
    print(f"   é¢„æµ‹å‡½æ•° - æ ·æœ¬æ•°: {len(pred_result['y_true'])}, å‡†ç¡®ç‡: {pred_result['accuracy']:.4f}")
    print()
    print(f"   å‡†ç¡®ç‡å·®å¼‚: {abs(eval_result['accuracy'] - pred_result['accuracy']):.4f}")
    
    if abs(eval_result['accuracy'] - pred_result['accuracy']) > 0.1:
        print("âŒ å‘ç°æ˜¾è‘—å·®å¼‚ï¼")
        print("   å¯èƒ½çš„åŸå› :")
        print("   1. æ•°æ®é¢„å¤„ç†ä¸ä¸€è‡´")
        print("   2. æ•°æ®åŠ è½½æ–¹å¼ä¸åŒ")
        print("   3. æ¨¡å‹æ¨ç†ç¯å¢ƒä¸åŒ")
    else:
        print("âœ… ç»“æœåŸºæœ¬ä¸€è‡´")
    
    # è¯¦ç»†å¯¹æ¯”é¢„æµ‹åˆ†å¸ƒ
    print(f"\né¢„æµ‹åˆ†å¸ƒå¯¹æ¯”:")
    eval_counter = Counter(eval_result['y_pred'])
    pred_counter = Counter(pred_result['y_pred'])
    
    all_classes = set(eval_counter.keys()) | set(pred_counter.keys())
    for class_id in sorted(all_classes):
        eval_count = eval_counter.get(class_id, 0)
        pred_count = pred_counter.get(class_id, 0)
        print(f"   ç±»åˆ«{class_id}: è¯„ä¼°å‡½æ•°={eval_count}, é¢„æµ‹å‡½æ•°={pred_count}, å·®å¼‚={abs(eval_count-pred_count)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯¹æ¯”è¯„ä¼°å‡½æ•°å’Œé¢„æµ‹å‡½æ•°åœ¨ç±»åˆ«9ä¸Šçš„è¡¨ç°...")
    print("="*60)
    
    try:
        # æµ‹è¯•è¯„ä¼°å‡½æ•°
        eval_result = test_with_evaluation_function()
        
        # æµ‹è¯•é¢„æµ‹å‡½æ•°
        pred_result = test_with_prediction_function()
        
        # å¯¹æ¯”ç»“æœ
        compare_results(eval_result, pred_result)
        
        print("="*60)
        print("ğŸ¯ æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
