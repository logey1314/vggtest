"""
è®­ç»ƒå·¥å…·å‡½æ•°
æä¾›è®­ç»ƒç®¡ç†ç›¸å…³çš„é€šç”¨åŠŸèƒ½
"""

import os
import yaml
import datetime
import logging
from typing import Dict, Tuple, Optional, List


def validate_resume_config(config: Dict) -> Tuple[bool, str]:
    """
    éªŒè¯æ¢å¤è®­ç»ƒé…ç½®
    
    Args:
        config (Dict): é…ç½®å­—å…¸
        
    Returns:
        Tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
    """
    resume_config = config.get('resume', {})
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ¢å¤è®­ç»ƒ
    if not resume_config.get('enabled', False):
        return False, "æ¢å¤è®­ç»ƒæœªå¯ç”¨ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® resume.enabled: true"
    
    # æ£€æŸ¥å¿…è¦çš„é…ç½®é¡¹
    required_keys = ['training', 'data', 'model', 'dataloader']
    missing_keys = [key for key in required_keys if key not in config]
    if missing_keys:
        return False, f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦é¡¹: {missing_keys}"
    
    # æ£€æŸ¥è®­ç»ƒé…ç½®
    training_config = config['training']
    if 'epochs' not in training_config or training_config['epochs'] <= 0:
        return False, "è®­ç»ƒè½®æ•°é…ç½®æ— æ•ˆï¼Œè¯·è®¾ç½® training.epochs ä¸ºæ­£æ•´æ•°"
    
    # æ£€æŸ¥æ•°æ®é…ç½®
    data_config = config['data']
    required_data_keys = ['num_classes', 'class_names', 'annotation_file']
    missing_data_keys = [key for key in required_data_keys if key not in data_config]
    if missing_data_keys:
        return False, f"æ•°æ®é…ç½®ç¼ºå°‘å¿…è¦é¡¹: {missing_data_keys}"
    
    # æ£€æŸ¥ç±»åˆ«æ•°é‡ä¸ç±»åˆ«åç§°æ˜¯å¦åŒ¹é…
    num_classes = data_config['num_classes']
    class_names = data_config['class_names']
    if len(class_names) != num_classes:
        return False, f"ç±»åˆ«æ•°é‡({num_classes})ä¸ç±»åˆ«åç§°æ•°é‡({len(class_names)})ä¸åŒ¹é…"
    
    return True, "é…ç½®éªŒè¯é€šè¿‡"


def setup_training_directories(project_root: str, config: Dict, 
                              prefix: str = "resume") -> Dict[str, str]:
    """
    è®¾ç½®è®­ç»ƒç›¸å…³ç›®å½•
    
    Args:
        project_root (str): é¡¹ç›®æ ¹ç›®å½•
        config (Dict): é…ç½®å­—å…¸
        prefix (str): ç›®å½•å‰ç¼€
        
    Returns:
        Dict[str, str]: ç›®å½•è·¯å¾„å­—å…¸
    """
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # åŸºç¡€ç›®å½•
    base_checkpoint_dir = os.path.join(project_root, config['save']['checkpoint_dir'])
    base_log_dir = os.path.join(project_root, config['logging']['log_dir'])
    base_plot_dir = os.path.join(project_root, config['logging']['plot_dir'])
    
    # æ—¶é—´æˆ³ç›®å½•
    checkpoint_dir = os.path.join(base_checkpoint_dir, f"{prefix}_{timestamp}")
    log_dir = os.path.join(base_log_dir, f"{prefix}_{timestamp}")
    plot_dir = os.path.join(base_plot_dir, f"{prefix}_{timestamp}")
    
    # latestç›®å½•
    latest_checkpoint_dir = os.path.join(base_checkpoint_dir, "latest")
    latest_log_dir = os.path.join(base_log_dir, "latest")
    latest_plot_dir = os.path.join(base_plot_dir, "latest")
    
    # åˆ›å»ºæ‰€æœ‰ç›®å½•
    directories = {
        'checkpoint_dir': checkpoint_dir,
        'log_dir': log_dir,
        'plot_dir': plot_dir,
        'latest_checkpoint_dir': latest_checkpoint_dir,
        'latest_log_dir': latest_log_dir,
        'latest_plot_dir': latest_plot_dir,
        'timestamp': timestamp
    }
    
    for dir_path in [checkpoint_dir, log_dir, plot_dir, 
                     latest_checkpoint_dir, latest_log_dir, latest_plot_dir]:
        os.makedirs(dir_path, exist_ok=True)
    
    return directories


def backup_config_file(config: Dict, backup_dir: str, 
                      filename: str = "config_backup.yaml") -> str:
    """
    å¤‡ä»½é…ç½®æ–‡ä»¶
    
    Args:
        config (Dict): é…ç½®å­—å…¸
        backup_dir (str): å¤‡ä»½ç›®å½•
        filename (str): å¤‡ä»½æ–‡ä»¶å
        
    Returns:
        str: å¤‡ä»½æ–‡ä»¶è·¯å¾„
    """
    backup_path = os.path.join(backup_dir, filename)
    
    with open(backup_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    return backup_path


def setup_training_logger(log_dir: str, timestamp: str, 
                         script_name: str = "training") -> logging.Logger:
    """
    è®¾ç½®è®­ç»ƒæ—¥å¿—è®°å½•å™¨
    
    Args:
        log_dir (str): æ—¥å¿—ç›®å½•
        timestamp (str): æ—¶é—´æˆ³
        script_name (str): è„šæœ¬åç§°
        
    Returns:
        logging.Logger: é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨
    """
    log_file = os.path.join(log_dir, f'{script_name}.log')
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    logger = logging.getLogger(script_name)
    logger.info("="*80)
    logger.info(f"ğŸ”„ {script_name} å¼€å§‹")
    logger.info("="*80)
    logger.info(f"è®­ç»ƒæ—¶é—´æˆ³: {timestamp}")
    logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    return logger


def print_training_summary(config: Dict, directories: Dict, 
                          checkpoint_path: str = None):
    """
    æ‰“å°è®­ç»ƒæ‘˜è¦ä¿¡æ¯
    
    Args:
        config (Dict): é…ç½®å­—å…¸
        directories (Dict): ç›®å½•å­—å…¸
        checkpoint_path (str): æ£€æŸ¥ç‚¹è·¯å¾„
    """
    print(f"ğŸ“Š è®­ç»ƒé…ç½®æ‘˜è¦:")
    print(f"   ç›®æ ‡è½®æ•°: {config['training']['epochs']}")
    print(f"   å­¦ä¹ ç‡: {config['training']['learning_rate']}")
    print(f"   æ‰¹æ¬¡å¤§å°: {config['dataloader']['batch_size']}")
    print(f"   ç±»åˆ«æ•°é‡: {config['data']['num_classes']}")
    print(f"   ä¼˜åŒ–å™¨: {config['training']['optimizer']}")
    print(f"   è°ƒåº¦å™¨: {config['training']['scheduler']['type']}")
    
    if checkpoint_path:
        print(f"\nğŸ¯ æ£€æŸ¥ç‚¹ä¿¡æ¯:")
        print(f"   æ£€æŸ¥ç‚¹æ–‡ä»¶: {checkpoint_path}")
    
    print(f"\nğŸ’¾ è¾“å‡ºç›®å½•:")
    print(f"   æ£€æŸ¥ç‚¹: {directories['checkpoint_dir']}")
    print(f"   æ—¥å¿—: {directories['log_dir']}")
    print(f"   å›¾è¡¨: {directories['plot_dir']}")


def check_training_prerequisites(project_root: str, config: Dict) -> Tuple[bool, List[str]]:
    """
    æ£€æŸ¥è®­ç»ƒå‰ç½®æ¡ä»¶
    
    Args:
        project_root (str): é¡¹ç›®æ ¹ç›®å½•
        config (Dict): é…ç½®å­—å…¸
        
    Returns:
        Tuple[bool, List[str]]: (æ˜¯å¦æ»¡è¶³æ¡ä»¶, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
    """
    errors = []
    
    # æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶
    annotation_path = os.path.join(project_root, config['data']['annotation_file'])
    if not os.path.exists(annotation_path):
        errors.append(f"æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {annotation_path}")
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = os.path.join(project_root, config['data']['data_dir'])
    if not os.path.exists(data_dir):
        errors.append(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶å¿…è¦é¡¹
    required_sections = ['training', 'data', 'model', 'dataloader', 'save', 'logging']
    for section in required_sections:
        if section not in config:
            errors.append(f"é…ç½®æ–‡ä»¶ç¼ºå°‘ {section} éƒ¨åˆ†")
    
    # æ£€æŸ¥ä¿å­˜ç›®å½•æƒé™
    try:
        checkpoint_base = os.path.join(project_root, config['save']['checkpoint_dir'])
        os.makedirs(checkpoint_base, exist_ok=True)
        
        log_base = os.path.join(project_root, config['logging']['log_dir'])
        os.makedirs(log_base, exist_ok=True)
        
        plot_base = os.path.join(project_root, config['logging']['plot_dir'])
        os.makedirs(plot_base, exist_ok=True)
        
    except PermissionError as e:
        errors.append(f"ç›®å½•åˆ›å»ºæƒé™ä¸è¶³: {e}")
    except Exception as e:
        errors.append(f"ç›®å½•åˆ›å»ºå¤±è´¥: {e}")
    
    return len(errors) == 0, errors


def format_time_duration(seconds: float) -> str:
    """
    æ ¼å¼åŒ–æ—¶é—´æŒç»­æ—¶é—´
    
    Args:
        seconds (float): ç§’æ•°
        
    Returns:
        str: æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
    """
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        minutes = seconds / 60
        return f"{minutes:.1f}åˆ†é’Ÿ"
    else:
        hours = seconds / 3600
        return f"{hours:.1f}å°æ—¶"


def calculate_eta(current_epoch: int, total_epochs: int, 
                 elapsed_time: float) -> str:
    """
    è®¡ç®—é¢„è®¡å‰©ä½™æ—¶é—´
    
    Args:
        current_epoch (int): å½“å‰è½®æ•°
        total_epochs (int): æ€»è½®æ•°
        elapsed_time (float): å·²ç”¨æ—¶é—´ï¼ˆç§’ï¼‰
        
    Returns:
        str: é¢„è®¡å‰©ä½™æ—¶é—´å­—ç¬¦ä¸²
    """
    if current_epoch == 0:
        return "è®¡ç®—ä¸­..."
    
    avg_time_per_epoch = elapsed_time / current_epoch
    remaining_epochs = total_epochs - current_epoch
    eta_seconds = avg_time_per_epoch * remaining_epochs
    
    return format_time_duration(eta_seconds)


def get_training_status_summary(current_epoch: int, total_epochs: int,
                               train_acc: float, val_acc: float,
                               best_acc: float, elapsed_time: float) -> str:
    """
    è·å–è®­ç»ƒçŠ¶æ€æ‘˜è¦
    
    Args:
        current_epoch (int): å½“å‰è½®æ•°
        total_epochs (int): æ€»è½®æ•°
        train_acc (float): è®­ç»ƒå‡†ç¡®ç‡
        val_acc (float): éªŒè¯å‡†ç¡®ç‡
        best_acc (float): æœ€ä½³å‡†ç¡®ç‡
        elapsed_time (float): å·²ç”¨æ—¶é—´
        
    Returns:
        str: çŠ¶æ€æ‘˜è¦å­—ç¬¦ä¸²
    """
    progress = (current_epoch / total_epochs) * 100
    eta = calculate_eta(current_epoch, total_epochs, elapsed_time)
    elapsed_str = format_time_duration(elapsed_time)
    
    summary = f"""
ğŸ“Š è®­ç»ƒçŠ¶æ€æ‘˜è¦ (Epoch {current_epoch}/{total_epochs})
{'='*50}
è¿›åº¦: {progress:.1f}% 
è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.2f}%
éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%
æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%
å·²ç”¨æ—¶é—´: {elapsed_str}
é¢„è®¡å‰©ä½™: {eta}
{'='*50}
"""
    return summary
