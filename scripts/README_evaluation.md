# 模型评估脚本使用说明

本文档介绍如何使用 `evaluate_model.py` 脚本对训练好的混凝土坍落度分类模型进行全面评估。

## 🎯 脚本功能

`evaluate_model.py` 提供以下功能：
- 加载训练好的模型权重
- 在测试数据集上进行预测
- 计算全面的评估指标
- 生成详细的可视化分析
- 输出专业的评估报告

## 🚀 使用方法

### 基础使用

```bash
# 在项目根目录下运行
python scripts/evaluate_model.py
```

### 前提条件

1. **已完成模型训练**：确保存在训练好的模型文件
2. **模型文件位置**：默认使用 `models/checkpoints/best_model.pth`
3. **数据集准备**：确保测试数据和标注文件存在

## 📁 文件路径配置

脚本会自动使用以下路径：

```python
# 配置文件
config_path = 'configs/training_config.yaml'

# 模型文件（可修改）
model_path = 'models/checkpoints/best_model.pth'

# 评估结果保存目录
save_dir = 'outputs/evaluation'
```

### 自定义模型路径

如需评估其他模型，修改脚本中的 `model_path` 变量：

```python
# 评估特定epoch的模型
model_path = os.path.join(project_root, 'models', 'checkpoints', 'checkpoint_epoch_50.pth')

# 评估其他目录的模型
model_path = '/path/to/your/model.pth'
```

## 📊 输出结果

### 控制台输出

脚本运行时会显示：
```
🚀 开始模型评估
================================================================================
📁 项目根目录: E:\project\vgg_test
📄 配置文件: E:\project\vgg_test\configs\training_config.yaml
🤖 模型文件: E:\project\vgg_test\models\checkpoints\best_model.pth
💾 保存目录: E:\project\vgg_test\outputs\evaluation
================================================================================

🖥️ 使用设备: cuda
📥 加载模型: E:\project\vgg_test\models\checkpoints\best_model.pth
✅ 模型加载成功

📊 数据集信息:
   总样本数: 23841
   批次大小: 4
   批次数量: 5961

🔍 开始模型评估...
评估进度: 100%|██████████| 5961/5961 [05:23<00:00, 18.42it/s]

✅ 评估完成
   总样本数: 23841
   预测准确率: 0.8756

🚀 开始生成综合评估报告...
📊 计算评估指标...
🔍 分析混淆矩阵...
❌ 分析错误样本...
📈 生成性能总览...
✅ 综合评估报告已生成完成！

================================================================================
📊 评估结果摘要
================================================================================
整体准确率: 0.8756
宏平均F1-Score: 0.8723
错误样本数: 2965
错误率: 0.1244
Top-2准确率: 0.9534
相邻类别混淆率: 0.0892
严重错误率: 0.0352

各类别性能:
  125-175mm: P=0.891, R=0.863, F1=0.877
  180-230mm: P=0.847, R=0.879, F1=0.863
  233-285mm: P=0.885, R=0.881, F1=0.883
================================================================================
🎉 评估完成！详细结果请查看保存的文件。
```

### 生成的文件

评估完成后，会在 `outputs/evaluation/` 目录下生成：

```
outputs/evaluation/
├── reports/
│   ├── evaluation_results.json      # 完整评估结果（JSON格式）
│   └── evaluation_report.txt        # 文本格式评估报告
├── confusion_matrices/
│   ├── confusion_matrix_counts.png       # 样本数量混淆矩阵
│   ├── confusion_matrix_recall.png       # 召回率视角混淆矩阵
│   ├── confusion_matrix_precision.png    # 精确率视角混淆矩阵
│   └── confusion_analysis.png            # 混淆分析综合图
├── error_analysis/
│   ├── error_analysis.png           # 错误分析图表
│   └── error_samples.png            # 错误样本可视化
└── performance_overview.png         # 性能总览图
```

## 📋 评估指标说明

### 核心指标

- **准确率 (Accuracy)**: 整体预测正确的比例
- **精确率 (Precision)**: 预测为正类的样本中实际为正类的比例
- **召回率 (Recall)**: 实际正类样本中被正确预测的比例
- **F1-Score**: 精确率和召回率的调和平均

### 混凝土坍落度特殊指标

- **相邻类别混淆率**: 相邻坍落度范围间的误分类率
- **严重错误率**: 跨范围严重误分类率（如125-175mm误分为233-285mm）
- **Top-2准确率**: 前两个预测结果包含正确答案的比例

### 各类别详细分析

每个坍落度范围的独立性能：
- **125-175mm**: 低坍落度范围性能
- **180-230mm**: 中坍落度范围性能  
- **233-285mm**: 高坍落度范围性能

## 🔧 自定义配置

### 修改评估参数

在脚本中可以调整以下参数：

```python
# 错误样本可视化数量
error_analyzer.visualize_error_samples(error_info, max_samples=20)

# 批次大小（如果内存不足）
config['dataloader']['batch_size'] = 2

# 评估结果保存目录
save_dir = "custom/evaluation/path"
```

### 评估特定数据集

如需评估特定数据集，修改标注文件路径：

```python
# 在配置文件中修改
data:
  annotation_file: "data/annotations/test_set.txt"
```

## ⚠️ 注意事项

1. **模型文件**: 确保模型文件存在且格式正确
2. **数据路径**: 检查图像路径在标注文件中是否正确
3. **内存使用**: 大数据集评估时注意内存占用
4. **设备兼容**: 脚本自动检测GPU，无GPU时使用CPU
5. **中文字体**: 如图表中文显示异常，请安装相应字体

## 🐛 常见问题

### 问题1: 模型文件不存在
```
❌ 模型文件不存在: models/checkpoints/best_model.pth
```
**解决方案**: 先完成模型训练或检查模型文件路径

### 问题2: 标注文件格式错误
```
❌ 标注文件不存在: data/annotations/cls_train.txt
```
**解决方案**: 检查标注文件路径和格式

### 问题3: 内存不足
```
CUDA out of memory
```
**解决方案**: 减小批次大小或使用CPU评估

### 问题4: 图像路径错误
```
无法加载图像
```
**解决方案**: 检查标注文件中的图像路径是否正确

## 📈 结果解读

### 优秀模型指标参考
- **准确率**: > 85%
- **各类别F1-Score**: > 80%
- **相邻混淆率**: < 10%
- **严重错误率**: < 5%

### 改进建议
- 如相邻混淆率高：增加数据增强或调整类别边界
- 如某类别性能差：增加该类别训练样本
- 如整体准确率低：考虑模型架构或训练策略调整

## 🎯 最佳实践

1. **定期评估**: 训练过程中定期评估模型性能
2. **多指标关注**: 不仅关注准确率，还要关注各类别平衡性
3. **错误分析**: 重点分析错误样本，指导模型改进
4. **结果保存**: 保存评估结果用于模型版本对比
5. **报告分享**: 使用生成的报告与团队分享评估结果
