"""
æ··æ·†çŸ©é˜µåˆ†æå’Œå¯è§†åŒ–æ¨¡å—
ä¸“é—¨é’ˆå¯¹æ··å‡åœŸåè½åº¦åˆ†ç±»ä»»åŠ¡çš„æ··æ·†çŸ©é˜µåˆ†æ
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import os


class ConfusionMatrixAnalyzer:
    """
    æ··æ·†çŸ©é˜µåˆ†æå™¨
    æä¾›æ··æ·†çŸ©é˜µçš„è®¡ç®—ã€å¯è§†åŒ–å’Œæ·±åº¦åˆ†æåŠŸèƒ½
    """
    
    def __init__(self, class_names=None):
        """
        åˆå§‹åŒ–æ··æ·†çŸ©é˜µåˆ†æå™¨
        
        Args:
            class_names (list): ç±»åˆ«åç§°åˆ—è¡¨
        """
        if class_names is None:
            self.class_names = ["125-175mm", "180-230mm", "233-285mm"]
        else:
            self.class_names = class_names
            
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
    
    def calculate_confusion_matrix(self, y_true, y_pred, normalize=None):
        """
        è®¡ç®—æ··æ·†çŸ©é˜µ
        
        Args:
            y_true (array): çœŸå®æ ‡ç­¾
            y_pred (array): é¢„æµ‹æ ‡ç­¾
            normalize (str): å½’ä¸€åŒ–æ–¹å¼ ('true', 'pred', 'all', None)
            
        Returns:
            numpy.ndarray: æ··æ·†çŸ©é˜µ
        """
        cm = confusion_matrix(y_true, y_pred)
        
        if normalize == 'true':
            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        elif normalize == 'pred':
            cm = cm.astype('float') / cm.sum(axis=0)
        elif normalize == 'all':
            cm = cm.astype('float') / cm.sum()
            
        return cm
    
    def plot_confusion_matrix(self, y_true, y_pred, normalize=None, 
                            save_path=None, title="æ··æ·†çŸ©é˜µ", figsize=(10, 8)):
        """
        ç»˜åˆ¶æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾
        
        Args:
            y_true (array): çœŸå®æ ‡ç­¾
            y_pred (array): é¢„æµ‹æ ‡ç­¾
            normalize (str): å½’ä¸€åŒ–æ–¹å¼
            save_path (str): ä¿å­˜è·¯å¾„
            title (str): å›¾è¡¨æ ‡é¢˜
            figsize (tuple): å›¾åƒå¤§å°
        """
        cm = self.calculate_confusion_matrix(y_true, y_pred, normalize)
        
        plt.figure(figsize=figsize)
        
        # é€‰æ‹©é¢œè‰²æ˜ å°„
        if normalize:
            fmt = '.2%' if normalize == 'all' else '.2f'
            cmap = 'Blues'
        else:
            fmt = 'd'
            cmap = 'Blues'
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        sns.heatmap(cm, 
                   annot=True, 
                   fmt=fmt, 
                   cmap=cmap,
                   xticklabels=self.class_names,
                   yticklabels=self.class_names,
                   cbar_kws={'label': 'æ ·æœ¬æ•°é‡' if not normalize else 'æ¯”ä¾‹'})
        
        plt.title(title, fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=14)
        plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=14)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        accuracy = np.trace(cm) / np.sum(cm) if not normalize else np.trace(cm)
        if normalize:
            plt.figtext(0.02, 0.02, f'å‡†ç¡®ç‡: {accuracy:.2%}', fontsize=12)
        else:
            plt.figtext(0.02, 0.02, f'æ€»æ ·æœ¬: {np.sum(cm)}, å‡†ç¡®ç‡: {accuracy:.2%}', fontsize=12)
        
        plt.tight_layout()
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š æ··æ·†çŸ©é˜µå·²ä¿å­˜: {save_path}")
        
        plt.show()
        return cm
    
    def plot_multiple_confusion_matrices(self, y_true, y_pred, save_dir=None):
        """
        ç»˜åˆ¶å¤šç§å½¢å¼çš„æ··æ·†çŸ©é˜µ
        
        Args:
            y_true (array): çœŸå®æ ‡ç­¾
            y_pred (array): é¢„æµ‹æ ‡ç­¾
            save_dir (str): ä¿å­˜ç›®å½•
        """
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
        
        # åŸå§‹æ•°é‡çŸ©é˜µ
        save_path1 = os.path.join(save_dir, "confusion_matrix_counts.png") if save_dir else None
        cm_counts = self.plot_confusion_matrix(
            y_true, y_pred, 
            normalize=None,
            save_path=save_path1,
            title="æ··æ·†çŸ©é˜µ - æ ·æœ¬æ•°é‡",
            figsize=(8, 6)
        )
        
        # æŒ‰çœŸå®æ ‡ç­¾å½’ä¸€åŒ–
        save_path2 = os.path.join(save_dir, "confusion_matrix_recall.png") if save_dir else None
        cm_recall = self.plot_confusion_matrix(
            y_true, y_pred,
            normalize='true',
            save_path=save_path2,
            title="æ··æ·†çŸ©é˜µ - å¬å›ç‡è§†è§’",
            figsize=(8, 6)
        )
        
        # æŒ‰é¢„æµ‹æ ‡ç­¾å½’ä¸€åŒ–
        save_path3 = os.path.join(save_dir, "confusion_matrix_precision.png") if save_dir else None
        cm_precision = self.plot_confusion_matrix(
            y_true, y_pred,
            normalize='pred',
            save_path=save_path3,
            title="æ··æ·†çŸ©é˜µ - ç²¾ç¡®ç‡è§†è§’",
            figsize=(8, 6)
        )
        
        return cm_counts, cm_recall, cm_precision
    
    def analyze_confusion_patterns(self, y_true, y_pred):
        """
        åˆ†ææ··æ·†æ¨¡å¼
        
        Args:
            y_true (array): çœŸå®æ ‡ç­¾
            y_pred (array): é¢„æµ‹æ ‡ç­¾
            
        Returns:
            dict: æ··æ·†æ¨¡å¼åˆ†æç»“æœ
        """
        cm = confusion_matrix(y_true, y_pred)
        total_samples = len(y_true)
        
        analysis = {
            'total_samples': total_samples,
            'correct_predictions': np.trace(cm),
            'accuracy': np.trace(cm) / total_samples
        }
        
        # å„ç±»åˆ«åˆ†æ
        for i, class_name in enumerate(self.class_names):
            class_total = np.sum(cm[i, :])  # è¯¥ç±»åˆ«çš„çœŸå®æ ·æœ¬æ€»æ•°
            class_correct = cm[i, i]        # è¯¥ç±»åˆ«çš„æ­£ç¡®é¢„æµ‹æ•°
            
            if class_total > 0:
                analysis[f'{class_name}_total'] = class_total
                analysis[f'{class_name}_correct'] = class_correct
                analysis[f'{class_name}_recall'] = class_correct / class_total
                
                # è¯¥ç±»åˆ«çš„ä¸»è¦æ··æ·†å¯¹è±¡
                wrong_predictions = cm[i, :].copy()
                wrong_predictions[i] = 0  # æ’é™¤æ­£ç¡®é¢„æµ‹
                if np.sum(wrong_predictions) > 0:
                    most_confused_idx = np.argmax(wrong_predictions)
                    most_confused_count = wrong_predictions[most_confused_idx]
                    analysis[f'{class_name}_most_confused_with'] = self.class_names[most_confused_idx]
                    analysis[f'{class_name}_most_confused_count'] = most_confused_count
        
        # æ•´ä½“æ··æ·†æ¨¡å¼
        # æ‰¾å‡ºæœ€å®¹æ˜“æ··æ·†çš„ç±»åˆ«å¯¹
        max_confusion = 0
        most_confused_pair = None
        for i in range(len(self.class_names)):
            for j in range(len(self.class_names)):
                if i != j and cm[i, j] > max_confusion:
                    max_confusion = cm[i, j]
                    most_confused_pair = (self.class_names[i], self.class_names[j])
        
        if most_confused_pair:
            analysis['most_confused_pair'] = most_confused_pair
            analysis['most_confused_count'] = max_confusion
        
        # ç›¸é‚»ç±»åˆ«æ··æ·†åˆ†æï¼ˆé’ˆå¯¹åè½åº¦çš„è¿ç»­æ€§ï¼‰
        adjacent_confusion = 0
        severe_confusion = 0
        
        # ç›¸é‚»æ··æ·†ï¼š0-1, 1-0, 1-2, 2-1
        adjacent_confusion += cm[0, 1] + cm[1, 0] + cm[1, 2] + cm[2, 1]
        
        # ä¸¥é‡æ··æ·†ï¼š0-2, 2-0
        severe_confusion += cm[0, 2] + cm[2, 0]
        
        analysis['adjacent_confusion_count'] = adjacent_confusion
        analysis['adjacent_confusion_rate'] = adjacent_confusion / total_samples
        analysis['severe_confusion_count'] = severe_confusion
        analysis['severe_confusion_rate'] = severe_confusion / total_samples
        
        return analysis
    
    def plot_confusion_analysis(self, y_true, y_pred, save_path=None):
        """
        ç»˜åˆ¶æ··æ·†åˆ†æå›¾è¡¨
        
        Args:
            y_true (array): çœŸå®æ ‡ç­¾
            y_pred (array): é¢„æµ‹æ ‡ç­¾
            save_path (str): ä¿å­˜è·¯å¾„
        """
        analysis = self.analyze_confusion_patterns(y_true, y_pred)
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. å„ç±»åˆ«å¬å›ç‡
        recalls = [analysis.get(f'{name}_recall', 0) for name in self.class_names]
        bars1 = ax1.bar(self.class_names, recalls, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
        ax1.set_title('å„ç±»åˆ«å¬å›ç‡', fontsize=14, fontweight='bold')
        ax1.set_ylabel('å¬å›ç‡')
        ax1.set_ylim(0, 1)
        for bar, recall in zip(bars1, recalls):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{recall:.2%}', ha='center', va='bottom')
        
        # 2. æ··æ·†ç±»å‹åˆ†å¸ƒ
        confusion_types = ['æ­£ç¡®åˆ†ç±»', 'ç›¸é‚»æ··æ·†', 'ä¸¥é‡æ··æ·†']
        correct = analysis['correct_predictions']
        adjacent = analysis['adjacent_confusion_count']
        severe = analysis['severe_confusion_count']
        other = analysis['total_samples'] - correct - adjacent - severe
        
        confusion_counts = [correct, adjacent, severe, other]
        confusion_labels = confusion_types + ['å…¶ä»–é”™è¯¯']
        colors = ['#2ECC71', '#F39C12', '#E74C3C', '#95A5A6']
        
        wedges, texts, autotexts = ax2.pie(confusion_counts, labels=confusion_labels, 
                                          colors=colors, autopct='%1.1f%%', startangle=90)
        ax2.set_title('æ··æ·†ç±»å‹åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        
        # 3. å„ç±»åˆ«æ ·æœ¬åˆ†å¸ƒ
        class_totals = [analysis.get(f'{name}_total', 0) for name in self.class_names]
        bars3 = ax3.bar(self.class_names, class_totals, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
        ax3.set_title('å„ç±»åˆ«æ ·æœ¬åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax3.set_ylabel('æ ·æœ¬æ•°é‡')
        for bar, total in zip(bars3, class_totals):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(class_totals)*0.01, 
                    f'{total}', ha='center', va='bottom')
        
        # 4. æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
        cm = confusion_matrix(y_true, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=self.class_names, yticklabels=self.class_names, ax=ax4)
        ax4.set_title('æ··æ·†çŸ©é˜µ', fontsize=14, fontweight='bold')
        ax4.set_xlabel('é¢„æµ‹æ ‡ç­¾')
        ax4.set_ylabel('çœŸå®æ ‡ç­¾')
        
        plt.tight_layout()
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š æ··æ·†åˆ†æå›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        plt.show()
        
        return analysis
